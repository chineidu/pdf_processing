services:
  database:
    image: postgres:17.5-bookworm
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - db_volume:/var/lib/postgresql/data
      # Mount initialization script to create API database or other needed DBs
      # Please ensure the script has proper permissions (e.g., chmod +x)
      # Run for the 1st time ONLY: chmod +x docker/init_databases.sh
      - type: bind
        source: ./docker/init_databases.sh
        target: /docker-entrypoint-initdb.d/init_databases.sh
        read_only: true
    healthcheck:
      test: pg_isready -U ${POSTGRES_USER:-taskflow} -d ${POSTGRES_DB:-taskflow_db}
      interval: 5s
      retries: 5
    networks:
      - default
    restart: unless-stopped

  local-rabbitmq:
    image: rabbitmq:4.1.2-management
    container_name: local-rabbitmq
    env_file: # Location of file(s) containing the env vars. Only accessed by the container.
      - .env
    ports:
      - 5672:5672
      - 15672:15672
    volumes: # Persist the data volume
      - rabbitmq_data:/var/lib/rabbitmq
      # Volume mapping for the config file
      # It contains the RabbitMQ configuration
      - ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: unless-stopped

  # Initialize RabbitMQ vhosts and permissions after it starts
  rabbitmq-init:
    image: curlimages/curl:latest
    depends_on:
      local-rabbitmq:
        condition: service_healthy
    entrypoint: /bin/sh
    command: ["/init_rabbitmq.sh"]
    volumes:
      - ./docker/init_rabbitmq.sh:/init_rabbitmq.sh:ro
    restart: "no"

  # Redis for caching
  redis:
    image: redis:8.2.3-bookworm
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - type: bind
        source: ./docker/redis.conf
        target: /usr/local/etc/redis/redis.conf
        read_only: true
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "redis", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # For Redis GUI management
  redisinsight:
    image: redis/redisinsight:latest
    ports:
      - "5540:5540"
    depends_on:
      - redis
    # Connection URL:
    # redis://:<password>@<host>:<port>/<db_number>
    # e.g. redis://:redis@redis:6379/0
    # Note: Use `redis` instead of `localhost` when connecting from within another container

  # MinIO for S3-compatible storage
  minio:
    image: minio/minio:latest
    platform: linux/arm64
    command: server /data --console-address ":9001"
    env_file:
      - .env
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY}
      # --- Automated AMQP Configuration ---
      # The '1' acts as the identifier matching the arn:minio:sqs::1:amqp in the init script
      - MINIO_NOTIFY_AMQP_ENABLE_1=on
      - MINIO_NOTIFY_AMQP_URL_1=amqp://guest:guest@local-rabbitmq:5672/storage_events
      # topic name = minio_events (matches the topic in config.yaml)
      - MINIO_NOTIFY_AMQP_EXCHANGE_1=minio_events
      - MINIO_NOTIFY_AMQP_EXCHANGE_TYPE_1=topic
      - MINIO_NOTIFY_AMQP_ROUTING_KEY_1=s3.objectcreated.put
      - MINIO_NOTIFY_AMQP_DELIVERY_MODE_1=2
      - MINIO_NOTIFY_AMQP_MANDATORY_1=off
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped

  # Create bucket in MinIO
  minio-mc:
    image: minio/mc:latest
    platform: linux/arm64
    env_file:
      - .env
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      minio:
        condition: service_healthy
      local-rabbitmq:
        condition: service_healthy
      rabbitmq-init:
        condition: service_completed_successfully
    # The entrypoint script will:
    # 1. Wait for MinIO to be ready
    # 2. Create the bucket if it doesn't exist
    # 3. Set up the event notification for RabbitMQ (for new object creation events)
    entrypoint:
      - /bin/sh
      - -c
      - |
        set -eu

        echo 'Waiting for MinIO server to initialize...'
        until mc alias set myminio http://minio:9000 $$MINIO_ROOT_USER $$MINIO_ROOT_PASSWORD; do
          sleep 2
        done

        echo 'Creating bucket...'
        mc mb myminio/$$AWS_S3_BUCKET --ignore-existing || true
        mc anonymous set private myminio/$$AWS_S3_BUCKET

        echo 'Adding bucket event notification for RabbitMQ...'
        attempts=1
        max_attempts=20
        until [ $$attempts -gt $$max_attempts ]; do
          if mc event add myminio/$$AWS_S3_BUCKET arn:minio:sqs::1:amqp --event put --ignore-existing; then
            break
          fi
          echo "Retrying event registration ($$attempts/$$max_attempts)..."
          attempts=$$((attempts + 1))
          sleep 2
        done

        echo 'Verifying bucket event notification...'
        events_output="$(mc event list myminio/$$AWS_S3_BUCKET || true)"
        echo "$$events_output"
        case "$$events_output" in
          *"arn:minio:sqs::1:amqp"*) ;;
          *)
            echo 'Failed to verify arn:minio:sqs::1:amqp notification'
            exit 1
            ;;
        esac

        echo 'Setup successfully completed.'
  jaeger:
    # For distributed tracing collection and visualization
    image: jaegertracing/jaeger:2.14.1
    container_name: jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true # enable OTLP receiver so Jaeger accepts OpenTelemetry traces
      - SPAN_STORAGE_TYPE=badger # use BadgerDB as the span storage backend (embedded KV store)
      - BADGER_EPHEMERAL=false # false = persist Badger data on disk; true = in-memory/ephemeral
      - BADGER_DIRECTORY_VALUE=/badger/data # path inside container for Badger value log
      - BADGER_DIRECTORY_KEY=/badger/key # path inside container for Badger key/LSM files
    ports:
      # Jaeger UI
      - "16686:16686"
      # OTLP gRPC receiver (for OpenTelemetry)
      - "4317:4317"
      # OTLP HTTP receiver
      - "4318:4318"
      # Jaeger Thrift receivers (legacy)
      - "14268:14268"
      - "14250:14250"
      # Zipkin receiver
      - "9411:9411"
    volumes:
      - jaeger_data:/badger
    restart: unless-stopped

  # api:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   command: >
  #     python -m src.api.app
  #   ports:
  #     - "8000:8000"
  #   env_file:
  #     - .env
  #   volumes:
  #     # Mount source code as read-only for live updates without rebuilding
  #     - ./src:/app/src:ro
  #   environment:
  #     # Override database host for Docker networking
  #     RABBITMQ_HOST: local-rabbitmq
  #     POSTGRES_HOST: database
  #     REDIS_HOST: redis
  #     AWS_S3_HOST: minio
  #   depends_on:
  #     database: # This service is the MOST important dependency
  #       condition: service_healthy
  #     local-rabbitmq:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #     minio:
  #       condition: service_healthy
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  #     interval: 10s
  #     retries: 5

  # worker:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   command: python -m src.rabbitmq.consumer
  #   # OR CLI: docker compose up --scale worker=2
  #   scale: 2
  #   env_file:
  #     - .env
  #   volumes:
  #     # Mount source code as read-only for live updates without rebuilding
  #     - ./src:/app/src:ro
  #   environment:
  #     # Override database host for Docker networking
  #     RABBITMQ_HOST: local-rabbitmq
  #     POSTGRES_HOST: database
  #     AWS_S3_HOST: minio
  #   depends_on:
  #     database: # This service is the MOST important dependency
  #       condition: service_healthy
  #     local-rabbitmq:
  #       condition: service_healthy
  #     minio:
  #       condition: service_healthy
  #   restart: unless-stopped

# Named volumes ONLY!
# Persist data outside the lifecycle of the container.
volumes:
  db_volume:
  rabbitmq_data:
  redis_data:
  minio_data:
  jaeger_data:
