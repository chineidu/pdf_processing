services:
  database:
    image: postgres:17.5-bookworm
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - db_volume:/var/lib/postgresql/data
      # Mount initialization script to create API database or other needed DBs
      # Please ensure the script has proper permissions (e.g., chmod +x)
      # Run for the 1st time ONLY: chmod +x docker/init_databases.sh
      - type: bind
        source: ./docker/init_databases.sh
        target: /docker-entrypoint-initdb.d/init_databases.sh
        read_only: true
    healthcheck:
      test: pg_isready -U ${POSTGRES_USER:-taskflow} -d ${POSTGRES_DB:-taskflow_db}
      interval: 5s
      retries: 5
    networks:
      - default
    restart: unless-stopped

  local-rabbitmq: # 1st service
    image: rabbitmq:4.1.2-management
    container_name: local-rabbitmq
    env_file: # Location of file(s) containing the env vars. Only accessed by the container.
      - .env
    ports:
      - 5672:5672
      - 15672:15672
    volumes: # Persist the data volume
      - rabbitmq_data:/var/lib/rabbitmq
      # Volume mapping for the config file
      # It contains the RabbitMQ configuration
      - ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: unless-stopped

  # Redis for caching
  redis:
    image: redis:8.2.3-bookworm
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - type: bind
        source: ./docker/redis.conf
        target: /usr/local/etc/redis/redis.conf
        read_only: true
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "redis", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # For Redis GUI management
  redisinsight:
    image: redis/redisinsight:latest
    ports:
      - "5540:5540"
    depends_on:
      - redis
    # Connection URL:
    # redis://:<password>@<host>:<port>/<db_number>
    # e.g. redis://:redis@redis:6379/0
    # Note: Use `redis` instead of `localhost` when connecting from within another container

  # MinIO for S3-compatible storage
  minio:
    image: minio/minio:latest
    platform: linux/arm64
    command: server /data --console-address ":9001"
    env_file:
      - .env
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped

  # Create bucket in MinIO
  minio-mc:
    image: minio/mc:latest
    platform: linux/arm64
    env_file:
      - .env
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO server to initialize...';
      until mc alias set myminio http://minio:9000 $$MINIO_ROOT_USER $$MINIO_ROOT_PASSWORD; do
        sleep 2;
      done;

      echo 'Creating bucket...';
      mc mb myminio/$$AWS_S3_BUCKET || true;
      mc anonymous set private myminio/$$AWS_S3_BUCKET;

      echo 'Configuring webhook...';
      mc admin config set myminio notify_webhook:webhook1 \
        endpoint='https://api.yourdomain.com/webhooks/storage' \
        queue_dir='/data/minio-events' \
        queue_limit='100000';

      echo 'Restarting MinIO service to apply configuration...';
      mc admin service restart myminio;

      echo 'Waiting for MinIO server to come back online...';
      until mc admin info myminio; do
        sleep 2;
      done;

      echo 'Adding bucket event notification...';
      mc event add myminio/$$AWS_S3_BUCKET \
        arn:minio:sqs::webhook1:webhook \
        --event put;

      echo 'Setup successfully completed.';
      exit 0;
      "
  jaeger:
    # For distributed tracing collection and visualization
    image: jaegertracing/jaeger:2.14.1
    container_name: jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true # enable OTLP receiver so Jaeger accepts OpenTelemetry traces
      - SPAN_STORAGE_TYPE=badger # use BadgerDB as the span storage backend (embedded KV store)
      - BADGER_EPHEMERAL=false # false = persist Badger data on disk; true = in-memory/ephemeral
      - BADGER_DIRECTORY_VALUE=/badger/data # path inside container for Badger value log
      - BADGER_DIRECTORY_KEY=/badger/key # path inside container for Badger key/LSM files
    ports:
      # Jaeger UI
      - "16686:16686"
      # OTLP gRPC receiver (for OpenTelemetry)
      - "4317:4317"
      # OTLP HTTP receiver
      - "4318:4318"
      # Jaeger Thrift receivers (legacy)
      - "14268:14268"
      - "14250:14250"
      # Zipkin receiver
      - "9411:9411"
    volumes:
      - jaeger_data:/badger
    restart: unless-stopped

  # api:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   command: >
  #     python -m src.api.app
  #   ports:
  #     - "8000:8000"
  #   env_file:
  #     - .env
  #   volumes:
  #     # Mount source code as read-only for live updates without rebuilding
  #     - ./src:/app/src:ro
  #   environment:
  #     # Override database host for Docker networking
  #     RABBITMQ_HOST: local-rabbitmq
  #     POSTGRES_HOST: database
  #     REDIS_HOST: redis
  #     AWS_S3_HOST: minio
  #   depends_on:
  #     database: # This service is the MOST important dependency
  #       condition: service_healthy
  #     local-rabbitmq:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #     minio:
  #       condition: service_healthy
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  #     interval: 10s
  #     retries: 5

  # worker:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   command: python -m src.rabbitmq.consumer
  #   # OR CLI: docker compose up --scale worker=2
  #   scale: 2
  #   env_file:
  #     - .env
  #   volumes:
  #     # Mount source code as read-only for live updates without rebuilding
  #     - ./src:/app/src:ro
  #   environment:
  #     # Override database host for Docker networking
  #     RABBITMQ_HOST: local-rabbitmq
  #     POSTGRES_HOST: database
  #     AWS_S3_HOST: minio
  #   depends_on:
  #     database: # This service is the MOST important dependency
  #       condition: service_healthy
  #     local-rabbitmq:
  #       condition: service_healthy
  #     minio:
  #       condition: service_healthy
  #   restart: unless-stopped

# Named volumes ONLY!
# Persist data outside the lifecycle of the container.
volumes:
  db_volume:
  rabbitmq_data:
  redis_data:
  minio_data:
  jaeger_data:
